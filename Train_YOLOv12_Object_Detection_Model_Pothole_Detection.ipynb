{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#**How to Train YOLOv12 Object Detection Model on a Custom Dataset**"],"metadata":{"id":"GXgn-y9H0VSS"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"KI4yr2YN0QdG"},"outputs":[],"source":["!nvidia-smi"]},{"cell_type":"markdown","source":["**Step 01 # Install the Required Packages**"],"metadata":{"id":"_5LLqcF-0cHJ"}},{"cell_type":"markdown","source":["**NOTE:** Currently, YOLOv12 does not have its own PyPI package, so we install it directly from GitHub and flash-attn (to accelerate attention-based computations via optimized CUDA kernels)."],"metadata":{"id":"acNT-_MR15e9"}},{"cell_type":"code","source":["!pip install -q git+https://github.com/sunsmarterjie/yolov12.git  flash-attn"],"metadata":{"collapsed":true,"id":"u2rUNstn0clw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Step 02 # Import All the Requried Libraries**"],"metadata":{"id":"4gdj-f220fXw"}},{"cell_type":"code","source":["import os\n","import ultralytics\n","ultralytics.checks()"],"metadata":{"id":"9M-MCrNR0fyG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from ultralytics import YOLO\n","from IPython.display import Image"],"metadata":{"id":"2LzVhEJC0hQJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["HOME = os.getcwd()\n","print(HOME)"],"metadata":{"id":"AZs-UOW38rFM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Step # 03 Download Dataset from Roboflow**"],"metadata":{"id":"Vqll1Mo30kP6"}},{"cell_type":"markdown","source":["https://universe.roboflow.com/muhammadmoin-arxtl/potholes-detection-jbnou/dataset/1"],"metadata":{"id":"Cthq1q6A4Ldl"}},{"cell_type":"code","source":["!pip install roboflow"],"metadata":{"id":"f2Rf1I_48MTc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from roboflow import Roboflow\n","# rf = Roboflow(api_key=\"C4bJWiCo5Qcs5teppFqY\")  # instructors key\n","rf = Roboflow(api_key=\"z1uD0b9XOZdnivUdFkEd\")  # my key\n","project = rf.workspace(\"muhammadmoin-arxtl\").project(\"potholes-detection-jbnou\")\n","version = project.version(1)\n","dataset = version.download(\"yolov12\")"],"metadata":{"id":"MKva7H-b0laL","collapsed":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!ls {dataset.location}"],"metadata":{"id":"DjfXyuy75BU5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dataset.location"],"metadata":{"id":"1T6IQChgmFwv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Step # 04 Fine-tune YOLOv12 model on a Custom Dataset**"],"metadata":{"id":"hekD9UTY4MV0"}},{"cell_type":"markdown","source":["**NOTE:** We need to make a few changes to our downloaded dataset so it will work with YOLOv12. Run the following bash commands to prepare your dataset for training by updating the relative paths in the `data.yaml` file, ensuring it correctly points to the subdirectories for your dataset's `train`, `test`, and `valid` subsets."],"metadata":{"id":"m0gby3H35oHy"}},{"cell_type":"code","source":["# Make a cpoy of the original data.yaml file, and display the file.\n","! cp {dataset.location}/data.yaml {dataset.location}/data-orig.yaml\n","! cat {dataset.location}/data.yaml"],"metadata":{"id":"ccoV8GdGcyqa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Delete the last 4 lines, and add 3 new lines at the end.\n","!sed -i '$d' {dataset.location}/data.yaml\n","!sed -i '$d' {dataset.location}/data.yaml\n","!sed -i '$d' {dataset.location}/data.yaml\n","!sed -i '$d' {dataset.location}/data.yaml\n","!echo -e \"test: ../test/images\\ntrain: ../train/images\\nval: ../valid/images\" >> {dataset.location}/data.yaml"],"metadata":{"id":"a4Kb9Et14GQo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!cat {dataset.location}/data.yaml"],"metadata":{"id":"fFaEY8rx5rOE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["We are now ready to fine-tune our YOLOv12 model. In the code below, we initialize the model using a starting checkpoint—here, we use `yolov12m.yaml`, but you can replace it with any other model (e.g., `yolov12n.pt`, `yolov12m.pt`, `yolov12l.pt`, or `yolov12x.pt`) based on your preference. We set the training to run for 50 epochs in this example; however, you should adjust the number of epochs along with other hyperparameters such as batch size, image size, and augmentation settings (scale, mosaic, mixup, and copy-paste) based on your hardware capabilities and dataset size.\n","\n","**Note:** **Note that after training, you might encounter a `TypeError: argument of type 'PosixPath' is not iterable error` — this is a known issue, but your model weights will still be saved, so you can safely proceed to running inference.**"],"metadata":{"id":"rga_41OO6Er6"}},{"cell_type":"code","source":["model = YOLO('yolov12m.yaml')\n","\n","results = model.train(data=f'{dataset.location}/data.yaml', epochs=50)"],"metadata":{"id":"hT2tO5YH6Qt9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Step # 05 Evaluate fine-tuned YOLOv12 model**\n"],"metadata":{"id":"XEAWbzgm8Uwd"}},{"cell_type":"code","source":["import locale\n","locale.getpreferredencoding = lambda: \"UTF-8\"\n","\n","!ls -la {HOME}/runs/detect/train/"],"metadata":{"id":"DVvwiS8r6w3T"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Image(filename=f'{HOME}/runs/detect/train/confusion_matrix.png', width=1000)"],"metadata":{"id":"YK6KK-Hi8g7j"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Image(filename=f'{HOME}/runs/detect/train/confusion_matrix_normalized.png', width=1000)"],"metadata":{"id":"W-pBwFjY9MN_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Image(filename=f'{HOME}/runs/detect/train/results.png', width=1000)"],"metadata":{"id":"7deRc4an8wBO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Precision = TP / (TP + FP)\n","\n","Precision is simply true positives out of total detections.\n"],"metadata":{"id":"NGm4YstvzWPH"}},{"cell_type":"code","source":["Image(filename=f'{HOME}/runs/detect/train/P_curve.png', width=600)"],"metadata":{"id":"TacArI6I89RS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Recall = TP / (TP + FN)\n","\n","Recall is the True Positive out of all Ground Truths"],"metadata":{"id":"pbbL04NRzu0z"}},{"cell_type":"code","source":["Image(filename=f'{HOME}/runs/detect/train/R_curve.png', width=600)"],"metadata":{"id":"-oYrKBUT8_eN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Image(filename=f'{HOME}/runs/detect/train/train_batch0.jpg', width=1000)"],"metadata":{"id":"eEk48yFH9bAk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Image(filename=f'{HOME}/runs/detect/train/val_batch1_pred.jpg', width=1000)"],"metadata":{"id":"boTyA1x69eca"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Image(filename=f'{HOME}/runs/detect/train/val_batch2_pred.jpg', width=1000)"],"metadata":{"id":"srNkIS4z9jdf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n"],"metadata":{"id":"z9cjEWCf_b7q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Move the best model weights to our Google drive\n","! mv \"/content/runs/detect/train/weights/best.pt\" \"/content/drive/MyDrive/Colab Notebooks/2025/Udemy/YOLO-12\""],"metadata":{"id":"G07q09JB_lKs"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Step # 06 Download the Model Weights from the Google Drive**"],"metadata":{"id":"22PeMoy_9toi"}},{"cell_type":"code","source":["# !gdown \"https://drive.google.com/uc?id=1R77i29Yywnl-auv3iTrSeO_yjIkHMy30&confirm=t\"\n","# Must download my weights, not the instructors - his weights do not work"],"metadata":{"id":"nuVaUS9h9sb8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Step # 07  Validate Fine-Tuned Model**"],"metadata":{"id":"RgnmSB3x9wfa"}},{"cell_type":"code","source":["model = YOLO(\"best.pt\")  # load a custom model\n","\n","# Validate the model\n","metrics = model.val()  # no arguments needed, dataset and settings remembered\n","metrics.box.map  # map50-95\n","metrics.box.map50  # map50\n","metrics.box.map75  # map75\n","metrics.box.maps  # a list contains map50-95 of each category"],"metadata":{"id":"M0XfI1Iq9wAi"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Step # 08 Inference with Custom Model on Test Dataset Images**"],"metadata":{"id":"e8EFYvNB-eTk"}},{"cell_type":"code","source":["dataset.location"],"metadata":{"id":"-8qkJ3x1Lm8t"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["results = model.predict(source = f\"{dataset.location}/test/images\", save = True, iou = 0.1)"],"metadata":{"id":"C3rxTUQ6-emB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import glob\n","import os\n","from IPython.display import Image as IPyImage, display\n","\n","latest_folder = max(glob.glob(f'{HOME}/runs/detect/predict*/'), key=os.path.getmtime)\n","\n","for img in glob.glob(f'{latest_folder}/*.jpg')[1:10]:\n","    display(IPyImage(filename=img, width=600))\n","    print(\"\\n\")"],"metadata":{"id":"1qXyvHlh_aT_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["HOME"],"metadata":{"id":"NSGPQteJACzs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ! cat /content/Potholes-Detection-1/test/images/img-366_jpg.rf.d35db5bb660c7bedd50c5f698fff1795.jpg"],"metadata":{"id":"RJrsgDLJA3-y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import cv2\n","import numpy as np\n","from google.colab.patches import cv2_imshow\n","\n","# Load an image\n","# image = cv2.imread('path/to/your/image.jpg')\n","image = cv2.imread('/content/Potholes-Detection-1/test/images/img-366_jpg.rf.d35db5bb660c7bedd50c5f698fff1795.jpg')\n","\n","# Check if image loading was successful\n","if image is None:\n","    print(\"Error: Could not load image.\")\n","else:\n","    # Define the coordinates for the bounding box\n","    # (x, y) is the top-left corner of the rectangle\n","    # (x + width, y + height) is the bottom-right corner\n","    x, y, w, h = 100, 275, 450, 200  # Example coordinates: (100, 50) top-left, width 150, height 200\n","\n","    # x, y, w, h = 0.4265625, 0.61328125, 0.81796875, 0.41328125\n","\n","    # Draw the rectangle\n","    # Arguments:\n","    # 1. image: The image on which to draw\n","    # 2. (x, y): Top-left corner coordinates\n","    # 3. (x + w, y + h): Bottom-right corner coordinates\n","    # 4. (B, G, R): Color of the rectangle in BGR format (e.g., (0, 255, 0) for green)\n","    # 5. thickness: Thickness of the rectangle border (e.g., 2 for a 2-pixel thick line)\n","    cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n","\n","    # Display the image with the bounding box\n","    cv2_imshow(image)\n","    # cv2.waitKey(0)  # Wait indefinitely until a key is pressed\n","    # cv2.destroyAllWindows()"],"metadata":{"id":"ZiI0iZfJAC2m"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"1RhOQRVSADaX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Step # 09 Inference with Custom Model on Videos**"],"metadata":{"id":"5rEFzXSr_jnm"}},{"cell_type":"code","source":["import locale\n","locale.getpreferredencoding = lambda: \"UTF-8\""],"metadata":{"id":"_NBH_iDM8Eyl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!gdown \"https://drive.google.com/uc?id=1iMitK9VCUWmBcZiiEPHK1d2pydALof6s&confirm=t\""],"metadata":{"id":"yxPFDqXY_k_K"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["results = model.predict(source = f\"/{HOME}/demo.mp4\", save = True, iou = 0.1)"],"metadata":{"id":"ggMln7IC_qKF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!rm '/content/result_compressed.mp4'"],"metadata":{"id":"iuTlW2fw_4LD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from IPython.display import HTML\n","from base64 import b64encode\n","import os\n","\n","# Input video path\n","save_path = f'{HOME}/runs/detect/predict/demo.avi'\n","\n","# Compressed video path\n","compressed_path = \"/content/result_compressed.mp4\"\n","\n","os.system(f\"ffmpeg -i {save_path} -vcodec libx264 {compressed_path}\")\n","\n","# Show video\n","mp4 = open(compressed_path,'rb').read()\n","data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n","HTML(\"\"\"\n","<video width=400 controls>\n","      <source src=\"%s\" type=\"video/mp4\">\n","</video>\n","\"\"\" % data_url)"],"metadata":{"id":"iFSg_fY4_4wG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"J4ZVR1bxNcq4"},"execution_count":null,"outputs":[]}]}